{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed packages to install\n",
    "#!pip install texthero==1.0.5\n",
    "#!pip install gensim\n",
    "#!pip install openpyxl \n",
    "#!pip install bnlp_toolkit\n",
    "#!pip install python-bidi\n",
    "#!pip install texthero\n",
    "#!pip install bangla-stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bidi.algorithm import get_display\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "from bnlp.corpus import stopwords, punctuations\n",
    "import texthero as hero\n",
    "import bnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('dataset/multi class bangla social media comment.xlsx')\n",
    "df.to_csv('dataset/multi_class_bangla_social_media_comment.csv', encoding='utf-8', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'comment react number': 'comment_react_number'})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "Category_counts=df.Category.value_counts()\n",
    "Gender_counts=df.Gender.value_counts()\n",
    "Comment_react_counts=df.comment_react_number.value_counts()\n",
    "label_counts=df.label.value_counts()\n",
    "print(Category_counts)\n",
    "print(\"\\n\",Gender_counts)\n",
    "print(\"\\n\",Comment_react_counts)\n",
    "print(\"\\n\",label_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub('[%s]' % re.escape(punctuations), ' ', text)     #escape punctuation\n",
    "    text = re.sub('\\n', ' ', text)                                 #replace line break with space\n",
    "    text = re.sub('\\w*\\d\\w*', ' ', text)                           #ignore digits\n",
    "    text = re.sub('\\xa0', ' ', text)                              \n",
    "    return text\n",
    "\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[\\u09E6-\\u09FF]+', ' ', text)                  #remove bangla punctuations\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['comment'].apply(lambda x: re.split('http:\\/\\/.*', str(x))) #remove urls\n",
    "df[\"text\"] = df['text'].apply(lambda x: clean(str(x)))                      \n",
    "df['text'] = df['text'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove special characters\n",
    "spec_chars = [\"!\",'\"',\"।\",\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
    "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "              \"`\",\"{\",\"|\",\"}\",\"~\",\"–\"]\n",
    "for char in spec_chars:\n",
    "    df['text'] = df['text'].str.replace(char, ' ') \n",
    "    df['text'] = df['text'].str.split().str.join(' ')         #remove whitespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking......\n",
    "df.text[2226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "custom_stop_word_list=['আমার ','অথচ ','অথবা ','অনুযায়ী ','অনেক ','অনেকে ','অনেকেই ','অন্তত ','অন্য ','অবধি ','অবশ্য ','অর্থাত ','আই ','আগামী ','আগে ','আগেই ','আছে ','আজ ','আদ্যভাগে ',\n",
    "                       'আপনার ','আপনারা ','আপনি ','আবার ','আসবে ','আমরা ',' আমাকে ','আমাদের ','আমার ','আমি ','আর ','আরও ','ইত্যাদি ','ইহা ','উচিত ','উত্তর ','উনি ','উপর ','উপরে ','এ ','এঁদের ','এঁরা ','এরা ',\n",
    "                       'এই ','একই ','একটি ','একবার ','একে ','এক্ ','এখন ','এখনও ','এখানে ','এখানেই ','এটা ','এটাই ','এটি ','এত ','এতটাই ','এতে ','এদের ','এব ','এবং ','এবার ','এমন ','এমনকী ',\n",
    "                       'এমনি ','এর ','এরা ','এল ','এস ','এসে ','ঐ ','ওঁদের ','ওঁর ','ওঁরা ','ওই ','ওকে ','ওখানে ','ওদের ','ওর ','ওরা ','কখনও ','কত ','কবে ','কমনে ','কয়েক ','কয়েকটি ','করছে ',\n",
    "                       'করছেন ','করতে ',' করবে',' করবেন',' করলে ',' করলেন',' করা',' করাই',' করায়',' করার',' করি','করতে ','করিতে ','করিয়া ','করিয়ে ','করে ','করেই ','করেছিলেন ','করেছে ','করেছেন ','করেন ',\n",
    "                       'কাউকে ','কাছ ','কাছে ','কাজ ','কাজে ','কারও ','কারণ ','কি ','কিংবা ','কিছু ','কিছুই ','হেতি ','কিন্তু ','ন্তু ','কী ','কে ','কেউ ','কেউই ','কেখা ','কেন ','কোটি ','কোন ','কোনও ',\n",
    "                       'কোনো ','ক্ষেত্রে ','কয়েক ','খুব ','গিয়ে ','গিয়েছে ','গেছেন ','গিয়ে ','গুলি ','গেছে ','গেল ','গেলে ','গোটা ','চলে ','চান ','চায় ','চার ','চালু ','চেয়ে ','চেষ্টা ','ছাড়া ','ছাড়াও ','ছিল ','ছিলেন ','জন ',\n",
    "                       'জনকে ','জনের ','জন্য ','জন্যওজে ','জানতে ','জানা ','জানানো ','জানায় ','জানিয়ে ','জানিয়েছে ','জ্নজন ','জন ','টা ','টি ','ঠিক ','তখন ','তত ','তথা ','তবু ','তবে ','তা ','তাঁকে ','তাঁদের ',\n",
    "                       'তাঁর ','তোর ','তাঁরা ','তাঁাহারা ','তাই ','যে ''তাও ','তাকে ','তাতে ','তাদের ','তার ','তারপর ','তারা ','তারৈ ','তাহলে ','তাহা ','তাহাতে ' ,'তাহার ','তিনঐ ','তিনি ','তিনিও ','তুমি ','তুলে ','তেমন ','তো ','তোমার ',\n",
    "                       'থাকবে ','থাকবেন ','থাকা ','থাকায় ','থাকে ','থাকেন ','থেকে ','থেকেই ','থেকেও ','দিকে ','দিতে ','দিন ','দিয়ে ','দিয়েছে ','দিয়েছেন ','দিলেন ', 'দু ','দুই ','দুটি ','দুটো ','দেওয়া ','দেওয়ার ','দেওয়া ',\n",
    "                       'দেখতে ','দেখা ','দেখে ','দেন ','দেয়া ','দেয় ','দ্বারা ','ধরা ','ধরে ','ধামার ','নতুন ','নাই ','নাকি ','নাগাদ ','নানা ','নিজে ','নিজেই ','নিজেদের ','নিজের ','নিতে ','নিয়ে ','নিয়ে ','নেই ','নেওয়া ','নেওয়ার ',\n",
    "                       'নেওয়া ','নয় ','পক্ষে ','পর ','পরে ','পরেই ','পরেও ','পর্যন্ত ','পাওয়া ','পাচ ','পারি ','পারে ','পারেন ','পেয়ে ','পেয়্র্ ','প্রতি ','প্রথম ','প্রভৃতি ','প্রযন্ত ','প্রাথমিক ','প্রায় ','প্রায় ','ফলে ','ফিরে ','ফের ',\n",
    "                       'বক্তব্য ','বদলে ','বন ','বরং ','বলতে ','বলছি ','বলল ','বললেন ','বলা ','বলে ','বলেছেন ','বলেন ','বসে ','বহু' ,'বাদে ','বার ','বিনা ','বিভিন্ন ','বিশেষ ','বিষয়টি ','বেশ ','বেশি ','ব্যবহার ','ব্যাপারে ','ভাবে ', 'ভাবেই ',\n",
    "                       'মতো ','মতোই ','মধ্যভাগে ','মধ্যে ','মধ্যেই ','মধ্যেও ','মনে ','মাত্র ','মাধ্যমে ','মোট ','মোটেই ','যখন ','যত ','যতটা ','যথেষ্ট ','যদি ','যদিও ','যা ','যাঁর ','যাঁরা ','যাওয়া ','যাওয়ার ','যাওয়া ','যাকে ','যাচ্ছে ',\n",
    "                       'যাতে ','যাদের ','যান ','যাবে ','যায় ','যার ','যারা ','যিনি ','অতএব ','যেখানে ','যেতে ','যেন ','যেমন ','রকম ','রয়েছে ','রাখা ','রেখে ','লক্ষ ','শুধু ','শুরু ','সঙ্গে ','সঙ্গেও ','সব ','সবার ','সবাইর ','সমস্ত ',\n",
    "                       'সম্প্রতি ','সহ ','সহিত ','সবই ','সাধারণ ','সামনে ','সুতরাং ','সবাইর ','সে ','সেই ','সেখান ','সেখানে ','সেটা ', 'সেটাই ','সেটাও ','সেটি ','স্পষ্ট ','স্বয়ং ','হইতে ','হইবে ','হইয়া ','হওয়া ','হওয়ায় ','হওয়ার ','হচ্ছে ','হত ','হতে ',\n",
    "                       'লেগেছে ','হতেই ','হন ','হইত ','হবে ','তিনি ','হবেন ','হয় ','হয়তো ','হয়নি ','হয়ে ','হয়েই ','হয়েছিল ','হয়েছে ','হয়েছেন ','হল ','হলে ','হলেই ','হলেও ','হলো ','হাজার ','হিসাবে ','হৈলে ','হোক ','হয় ']\n",
    "\n",
    "#digits=['০ ','১ ','২ ','৩ ','৪ ','৫ ','৬ ','৭ ','৮ ','৯ ']\n",
    "\n",
    "final_stopword_list = custom_stop_word_list \n",
    "#df['text']=df['text'].apply(lambda x: [item for item in x if item not in final_stopword_list])\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(final_stopword_list))\n",
    "df['text'] = df['text'].str.replace(pat, ' ')\n",
    "df['text'] = df['text'].str.replace(r'\\s+', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-michigan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking......\n",
    "df.text[2226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "regex = r\"[\\u0980-\\u09FF]+\"\n",
    "\n",
    "\n",
    "# Start with one review:\n",
    "df_NB = df[df['label']==\"not bully\"]\n",
    "df_TR = df[df['label']==\"troll\"]\n",
    "df_SE = df[df['label']==\"sexual\"]\n",
    "df_RE = df[df['label']==\"religious\"]\n",
    "df_TH = df[df['label']==\"threat\"]\n",
    "\n",
    "text_NB = \" \".join(review for review in df_NB.text)\n",
    "text_TR = \" \".join(review for review in df_TR.text)\n",
    "text_SE = \" \".join(review for review in df_SE.text)\n",
    "text_RE = \" \".join(review for review in df_RE.text)\n",
    "text_TH = \" \".join(review for review in df_TH.text)\n",
    "\n",
    "fig, ax = plt.subplots(5, 1, figsize  = (30,30))\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud_NB = WordCloud(font_path=\"BenSenHandwriting.ttf\",max_font_size=50,max_words=100,regexp=regex, background_color=\"white\").generate(text_NB)\n",
    "wordcloud_TR = WordCloud(font_path=\"MOHAO___.ttf\",max_font_size=50,max_words=100,regexp=regex, background_color=\"white\").generate(text_TR)\n",
    "wordcloud_SE = WordCloud(font_path=\"NikoshLight.ttf\",max_font_size=50,max_words=100,regexp=regex, background_color=\"white\").generate(text_SE)\n",
    "wordcloud_RE = WordCloud(font_path=\"MOHAO___.ttf\",max_font_size=50,max_words=100,regexp=regex, background_color=\"white\").generate(text_RE)\n",
    "wordcloud_TH = WordCloud(font_path=\"MOHAO___.ttf\",max_font_size=50,max_words=100,regexp=regex, background_color=\"white\").generate(text_TH)\n",
    "\n",
    "\n",
    "# Display the generated image:\n",
    "ax[0].imshow(wordcloud_NB, interpolation='bilinear')\n",
    "ax[0].set_title('Texts under Not Bully Class',fontsize=20)\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(wordcloud_TR, interpolation='bilinear')\n",
    "ax[1].set_title('Texts under Troll Class',fontsize=20)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(wordcloud_SE, interpolation='bilinear')\n",
    "ax[2].set_title('Texts Sexual Class',fontsize=20)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(wordcloud_RE, interpolation='bilinear')\n",
    "ax[3].set_title('Texts Religeous Class',fontsize=20)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(wordcloud_TH, interpolation='bilinear')\n",
    "ax[4].set_title('Texts Threat Class',fontsize=20)\n",
    "ax[4].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bangla_stemmer.stemmer.stemmer import BanglaStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnlp import BasicTokenizer,NLTKTokenizer\n",
    "from bangla_stemmer.stemmer.stemmer import BanglaStemmer\n",
    "\n",
    "\n",
    "b_token = BasicTokenizer()\n",
    "df['tokenized_text'] = df.apply(lambda row: b_token.tokenize(row['text']), axis=1)\n",
    "\n",
    "df['token_length'] = df.apply(lambda row: len(row['tokenized_text']), axis=1)\n",
    "\n",
    "df.head() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    stm = BanglaStemmer()\n",
    "    return [stm.stem(w) for w in df[\"tokenized_text\"]]\n",
    "\n",
    "df['comments_stem'] = df[\"tokenized_text\"].apply(lemmatize_text)\n",
    "df.head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['comment','comment_react_number','token_length',]\n",
    "df1=df.drop(col,axis=1)\n",
    "df1.to_csv('dataset/bangla_comments_tokenized.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['tokenized_text'].map(len) < 30]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-hygiene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-prairie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-springfield",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
